# redis

## redis缓存异常场景

- 缓存穿透
	描述： 缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，这时的用户很可能就是攻击者，攻击会导致数据库压力过大
	解决方案： 缓存空对象；布隆过滤器（推荐）
- 缓存击穿
	描述： 缓存击穿是指缓存中没有，但是数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没有读到数据，又同时去数据库中获取数据，引起数据库压力瞬间增大
	解决方案：设置热点数据永不过期；使用互斥锁排队；缓存屏障
- 缓存雪崩
	描述： 缓存在同一时间内大量键过期（失效），接着来的一大波请求瞬间落在数据库中导致连接异常
	解决方案： 互斥锁排对；缓存预热；双层缓存策略（原始缓存，拷贝缓存）
- 缓存预热
	描述：缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统，这样避免在用户请求时，先查询数据库，然后再将数据缓存的问题；
	解决方案： 数据量不大的时候，工程启动的时候进行加载缓存动作；
			数据量大的时候，设置一个定时任务任务脚本，进行缓存的刷新
			数据量太大的时候，优先保证热点数据进行提前加载到缓存
- 缓存降级
	描述： 降级的情况，就是缓存失效或者缓存服务器挂掉的情况下，我们也不去访问数据库，我们直接访问内存部分数据缓存或者直接返回默认数据 
	
	
## 单机版redis
1. 业务应用可以将redis当缓存来使用，从mysql中查询数据，然后写到redis中，之后业务应用在从redis中读取这些数据，由于redis的数据都存储在内存中，所以这个速度飞快；
2. 但是随着业务量增大，redis中存储的数据也越来越多，对redis的依赖越来越严重，但是如果你的redis因为某些原因宕机了，这时你的业务的所有的流量，都会打到后端的mysql上，这会导致你的mysql压力剧增，严重的会压垮mysql
3. 重启redis，因为之前的数据都在内存中，尽管重启redis，之前的数据也丢失了，重启后的redis虽然可以正常工作，但是由于redis中没有任何数据，业务流量都会打到后端的mysql上，mysql压力还是大
4. 既然redis只能把数据存储在内存中，那是否可以把这些数据也写一份到磁盘上，如果采用这种方式，当redis重启时，我们把磁盘的数据快速恢复到内存中，这样就可以继续提供正常服务了

## 数据持久化
1. redis每一次执行写操作，除了写内存之外，同时写一份到磁盘上
2. 客户端的每次操作，既要写内存，又要写磁盘，而写磁盘相对于写内存慢得多，这将会影响redis性能
3. 可以这样优化，redis写内存由主线程来做，写内存完成后就给客户端返回结果，然后redis用另外一个线程去写磁盘，这样避免主线程写磁盘对性能的影响
4. redis当作缓存使用，意味着redis没有保存全量的数据，对于不存在的数据，业务应用依旧可以通过查询后端数据库得到结果，只不过后端查询数据会慢一点，但对业务不影响
5. redis数据快照，是记录某一时刻redis中的数据，然后只需要把这个数据快照写到磁盘上就可以
6. 优势在于只需要持久化时，把数据一次性写入磁盘，其他时间不需要操作磁盘
7. AOF：每一次写操作都持久到磁盘(主线程写内存，根据策略可以配置由主线程还是子线程进行数据持久化)
8. RDB：只持久化某一时刻的数据快照到磁盘上（创建一个子进程来做）
9. AOF 记录的是每一次写命令，数据最全，但文件的体积大，数据恢复慢
10. RDB采用二进制+数据压缩的方式写磁盘，这样文件体积小，数据恢复速度快；
11. 这么一番优化之后，redis再也不用担心实例宕机了，当发生宕机时，你可以用持久化文件快速恢复redis中的数据
12. 虽然已经把持久化文件优化到最小了，但在恢复数据时依旧是需要时间的，在这期间的业务还是会受到影响
13. 一个实例宕机，只能用数据恢复来解决，那我们是否可以部署多个redis实例，然后这些实例数据时实同步，这样一个实例宕机后，我们在剩下的实例中选择一个继续提供服务就好

## 主从复制
1. 我们把实时读写的节点叫做master，另外一个实时同步数据节点叫做slave
2. 采用多副本的方案的优势是，缩短不可用时间，master发生宕机，我们可以手动将slave提升为master继续提供服务，提升读性能，让slave分担一部分读请求，提升应用的整体性能；
3. 当master发生宕机时，我们需要手动把slave提升为master，人工介入，也是需要消费时间的；
4.对于这种情况，我们需要一个故障自动切换机制，这就是我们经常听到的哨兵所具备的能力

## 哨兵：故障自动切换
1. 引入一个观察者实时监控master的健康状态，这个观察者就是哨兵
2. 哨兵每隔一段时间就询问master是否正常，master回复，表示正常，超时表示异常，哨兵发现异常，发起主从切换
3. 如果master状态正常，当这个哨兵在询问master时，他们之间的网络发生问题，那这个哨兵可能会误判
4. 我们可以部署多个哨兵，让他们分布在不同的机器上，让他们一起监控master的状态
5. 多个哨兵每间隔一段时间，询问master是否正常
6. master回复正常，表示状态正常，超时表示异常
7. 一旦一个哨兵判定master异常，就询问其他哨兵，如果多个哨兵都认为master异常了，这才判定master确实发生了故障
8. 多个哨兵经过协商，判定master故障，则发起主从切换
9. 选出一个哨兵领导者，由领导者进行主从切换
10. 每个哨兵都询问其他哨兵，请求对方为自己投票
11. 每个哨兵只投票给第一个请求投票的哨兵，且只能投票一次
12. 首先拿到超过半数的哨兵，成为领导者发起主从切换
13. 稳定性： redis宕机，有副本+哨兵，可以自动完成主从切换
14. 性能：读请求量增加，我们可以部署多个slave，读写分离，分担读压力
15. 性能： 写请求量增加，但我们只有一个master实例，这个实例达到瓶颈怎么办
16. 当你的写请求越来越大时，一个master实例可能就无法承担这么大的写流量了

## 分片集群
1. 一个实例抗不住写压力，那我们可以部署多个实例，然后把这些实例按照一定的规则组织起来，把他们当成一个整体，对外提供服务
2. 每个节点各自存储一部分数据，所有节点数据之和才是全数据
3. 制定一个路由规则（不同的key对应不同的实例），对于不同的key，把它路由到固定一个实例上进行读写
4. 客户端分片是指，key的路由规则放在客户端来做
5. 这个方案的缺点是，客户端需要维护这个路由规则，也就是需要将路由规则写到业务代码中
6. 如何不把路由规则耦合到业务代码中
7. 把这个路由规则封装成一个模块，当需要使用时，集成这个模块就行了
8. 服务端分片，指的是路由规则不放在客户端做，而是客户端和服务端之间增加一个中间代理层，这个代理就是我们经常听到的proxy,而数据的路由规则，就放在这个proxy层来维护，这样就无需关心服务端有多少个redis节点了，只需要和这个proxy交互即可
9. proxy会把你的请求根据路由规则，转发到对应的redis节点上，而且，当集群实例不足以支撑更大的流量请求时，还可以横向扩容，添加新的redis实例提升性能，这一切对于你的客户端来说，都是透明无感知的

